{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zarr creation using centre positions for multiSEM\n",
    "\n",
    "**NOTE**: I am trusting on the stitching parameters given by the adquisition software. This notebook only takes care of creating the last zarr for which I have to fuse the tiles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single hexagon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading centre position metadata from CVS file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multisemzarr as msz\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.io as skio\n",
    "#from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('/PROJECTS/CCI/BRAIN/Multibeam/Test_20Sections_20230217_15-17-11/Test_20Sections_20230217_15-17-11/')\n",
    "\n",
    "id = '024'\n",
    "region = 'Region4'\n",
    "section = id + '_' + region\n",
    "\n",
    "section_path = dataset_path.joinpath(section)\n",
    "\n",
    "csv_p = section_path.joinpath(region + \"_stitched_imagepositions.txt\")\n",
    "\n",
    "image_positions = msz.read_stitched_imagepositions(csv_p)\n",
    "image_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get information of each tile based on the naming convention of multiSEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_positions = msz.get_info_from_path(image_positions, section_path=section_path)\n",
    "\n",
    "image_positions.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume that al tiles have same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fill tile dimentions and positions based on first tile, we assume all othes have same size\n",
    "image_positions = msz.get_info_from_image(image_positions)\n",
    "# trasnlating to 0,0\n",
    "image_positions = msz.translation00(image_positions)\n",
    "\n",
    "image_positions.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intensity corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "if testing:\n",
    "\n",
    "    # this is for testing\n",
    "    hex_pos = image_positions[image_positions[\"hexagon\"].isin(['000011', \n",
    "                                                                '000012',\n",
    "                                                                '000013',\n",
    "                                                                '000014',\n",
    "                                                                '000015' ])].copy()\n",
    "    \n",
    "    hex_pos.reset_index(inplace=True)\n",
    "else:\n",
    "    # this is for full image\n",
    "    hex_pos = image_positions.copy()\n",
    "hex_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_pos = msz.get_intensity_correction(hex_pos, method='q30')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check size of array \n",
    "This is to make it compatible with downscaling later own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_pos = msz.translation00(hex_pos)\n",
    "\n",
    "x_size_tmp = (hex_pos['corner_x']+hex_pos[\"size_x\"]).max()\n",
    "total_x = int(msz.optimal_size(x_size_tmp, 5))\n",
    "\n",
    "y_size_tmp = (hex_pos['corner_y']+hex_pos[\"size_y\"]).max()\n",
    "total_y = int(msz.optimal_size(y_size_tmp, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Matplotlib figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#create simple line plot\n",
    "ax.scatter(hex_pos[\"centre_x\"].to_numpy(), hex_pos[\"centre_y\"].to_numpy())\n",
    "\n",
    "#add rectangle to plot\n",
    "for index, row in hex_pos.iterrows():\n",
    "    c_x = row[\"corner_x\"]\n",
    "    c_y = row[\"corner_y\"]\n",
    "    \n",
    "    ax.add_patch(Rectangle((c_x, c_y), row[\"size_x\"], row[\"size_y\"],\n",
    "             edgecolor = 'red',\n",
    "             fill=False))\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), total_x, total_y,\n",
    "             edgecolor = 'blue',\n",
    "             fill=False))\n",
    "\n",
    "# axis as in image\n",
    "ax.set_ylim(ax.get_ylim()[::-1])  \n",
    "ax.xaxis.tick_top() \n",
    "ax.yaxis.tick_left()  \n",
    "\n",
    "#display plot\n",
    "plt.title(\"Tile distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init ZARR array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_tree(pth):\n",
    "    pth = Path(pth)\n",
    "    for child in pth.glob('*'):\n",
    "        if child.is_file():\n",
    "            child.unlink()\n",
    "        else:\n",
    "            rm_tree(child)\n",
    "    pth.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_str = \"./data/\"+section+\".zarr\"\n",
    "z0_path = Path(z0_str)\n",
    "\n",
    "if z0_path.exists():\n",
    "  rm_tree(z0_path)\n",
    "  \n",
    "store = zarr.DirectoryStore(z0_path)\n",
    "img_tile = skio.imread(hex_pos['abs_path'][0])\n",
    "chunk_size = np.max(img_tile.shape)\n",
    "print(f'Chunk size: {chunk_size},{chunk_size}')\n",
    "z = zarr.creation.open_array(store=store, mode='a', shape=(total_y, total_x), chunks=(chunk_size,chunk_size), dtype=img_tile.dtype)\n",
    "z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamically fill in values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_write_tile3(tile_info, zarr_array):\n",
    "    from skimage.io import imread\n",
    "    from numpy import multiply, transpose, median\n",
    "    from multisemzarr import flat_field_correction\n",
    "    #if type(tile_info) is tuple:\n",
    "    #    tile_info = tile_info[1]\n",
    "\n",
    "    tile = imread(tile_info['abs_path'])\n",
    "    corr_tile = flat_field_correction(tile)\n",
    "\n",
    "    original_med = tile_info['median_int']\n",
    "    corr_med = median(corr_tile)\n",
    "\n",
    "    corr_tile = multiply(corr_tile, original_med/corr_med).astype(tile.dtype)\n",
    "    \n",
    "    x1 = tile_info[\"corner_x\"]\n",
    "    x2 = x1+tile_info[\"size_x\"]\n",
    "    y1 = tile_info[\"corner_y\"]\n",
    "    y2 = y1+tile_info[\"size_y\"]\n",
    "\n",
    "    corr_factor = tile_info['int_corr']\n",
    "\n",
    "    zarr_array[y1:y2,x1:x2] = multiply(transpose(corr_tile).astype(float), corr_factor).astype(zarr_array.dtype)\n",
    "\n",
    "def correct_write_tile2(tile_info, zarr_array):\n",
    "    from skimage.io import imread\n",
    "    from numpy import multiply, transpose, median\n",
    "    from skimage.exposure import equalize_adapthist\n",
    "    #if type(tile_info) is tuple:\n",
    "    #    tile_info = tile_info[1]\n",
    "\n",
    "    tile = imread(tile_info['abs_path'])\n",
    "\n",
    "    original_med = tile_info['median_int']\n",
    "    img_adapteq = equalize_adapthist(tile, clip_limit=0.00)\n",
    "    # img_adapteq.shape\n",
    "    adapted_med = median(img_adapteq)\n",
    "    img_adapteq = multiply(img_adapteq, original_med/adapted_med).astype(tile.dtype)\n",
    "    \n",
    "    x1 = tile_info[\"corner_x\"]\n",
    "    x2 = x1+tile_info[\"size_x\"]\n",
    "    y1 = tile_info[\"corner_y\"]\n",
    "    y2 = y1+tile_info[\"size_y\"]\n",
    "\n",
    "    corr_factor = tile_info['int_corr']\n",
    "\n",
    "    zarr_array[y1:y2,x1:x2] = multiply(transpose(img_adapteq).astype(float), corr_factor).astype(zarr_array.dtype)\n",
    "\n",
    "def correct_write_tile(tile_info, zarr_array):\n",
    "    from skimage.io import imread\n",
    "    from numpy import multiply, transpose\n",
    "    #if type(tile_info) is tuple:\n",
    "    #    tile_info = tile_info[1]\n",
    "\n",
    "    tile = imread(tile_info['abs_path'])\n",
    "    \n",
    "    x1 = tile_info[\"corner_x\"]\n",
    "    x2 = x1+tile_info[\"size_x\"]\n",
    "    y1 = tile_info[\"corner_y\"]\n",
    "    y2 = y1+tile_info[\"size_y\"]\n",
    "\n",
    "    corr_factor = tile_info['int_corr']\n",
    "\n",
    "    zarr_array[y1:y2,x1:x2] = multiply(transpose(tile).astype(float), corr_factor).astype(zarr_array.dtype)\n",
    "\n",
    "np.unique(hex_pos['tile_number'])\n",
    "chunks = []\n",
    "for tn in np.unique(hex_pos['tile_number']):\n",
    "    tmp = hex_pos[hex_pos['tile_number'].isin([tn])].copy()\n",
    "    chunks.append(tmp)\n",
    "\n",
    "print(f'found {len(chunks)} unique tile ids')\n",
    "\n",
    "for current in tqdm(chunks):\n",
    "    hex_list = []\n",
    "    for tile_idx, row in current.iterrows():\n",
    "        hex_list.append(row) \n",
    "\n",
    "    with Pool(20) as pool:\n",
    "        seq = [row for row in hex_list]\n",
    "        pool.map(partial(correct_write_tile3, zarr_array=z), seq)\n",
    "        #pool.imap(partial(correct_write_tile, zarr_array=z), seq)\n",
    "        #pool.close()\n",
    "        #pool.join()\n",
    "\n",
    "    #for row in hex_list:\n",
    "    #    print(row['int_corr'])\n",
    "    #    correct_write_tile(zarr_array=z, tile_info=row)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To open in napari\n",
    "\n",
    "This image can be now opened in Napari by drag a drop and using ```napari builtins```\n",
    "\n",
    "## Changing now to ome-zarr\n",
    "\n",
    "However, I want to add ome-zarr support. For that I need some minimal metadata, and optionally some resolution levels\n",
    "\n",
    "For downsampling I will use ```dask-array``` as suggested in [this discussion](https://forum.image.sc/t/creating-an-ome-zarr-dynamically-from-tiles-stored-as-a-series-of-images-list-of-centre-positions-using-python/81657/12?u=camachodejay) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "# like numpy.mean, but maintains dtype, helper function\n",
    "def mean_dtype(arr, **kwargs):\n",
    "    return np.mean(arr, **kwargs).astype(arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is still not quite clear to me why, but we need to rechunk de data at this stage\n",
    "# if not zarr writting later on will fail\n",
    "d0 = da.from_zarr(store).rechunk(img_tile.shape[1],img_tile.shape[0])\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = da.coarsen(mean_dtype, d0, {0:2,1:2}).rechunk(int(img_tile.shape[1]/2),int(img_tile.shape[0]/2))\n",
    "\n",
    "d2 = da.coarsen(mean_dtype, d0, {0:4,1:4}).rechunk(int(img_tile.shape[1]/2),int(img_tile.shape[0]/2))\n",
    "\n",
    "d3 = da.coarsen(mean_dtype, d0, {0:8,1:8}).rechunk(int(img_tile.shape[1]/2),int(img_tile.shape[0]/2))\n",
    "\n",
    "d4 = da.coarsen(mean_dtype, d0, {0:16,1:16}).rechunk(int(img_tile.shape[1]/2),int(img_tile.shape[0]/2))\n",
    "\n",
    "d5 = da.coarsen(mean_dtype, d0, {0:32,1:32}).rechunk(int(img_tile.shape[1]/2),int(img_tile.shape[0]/2))\n",
    "d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.writer import write_multiscale\n",
    "from ome_zarr.writer import write_multiscales_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can probably build this programmatically, for the moment I take a shortcut. \n",
    "# This assumes an image with full resolution and one downscale by 2x2\n",
    "initial_pix_size = 4\n",
    "initial_pix_unit = 'nanometer'\n",
    "coordtfs = [\n",
    "        [{'type': 'scale', 'scale': [initial_pix_size,initial_pix_size]},\n",
    "         {'type': 'translation', 'translation': [0, 0]}],\n",
    "        [{'type': 'scale', 'scale': [initial_pix_size*2,initial_pix_size*2]},\n",
    "         {'type': 'translation', 'translation': [0, 0]}],\n",
    "        [{'type': 'scale', 'scale': [initial_pix_size*4,initial_pix_size*4]},\n",
    "         {'type': 'translation', 'translation': [0, 0]}],\n",
    "        [{'type': 'scale', 'scale': [initial_pix_size*8,initial_pix_size*8]},\n",
    "         {'type': 'translation', 'translation': [0, 0]}],\n",
    "        [{'type': 'scale', 'scale': [initial_pix_size*16,initial_pix_size*16]},\n",
    "         {'type': 'translation', 'translation': [0, 0]}],\n",
    "        [{'type': 'scale', 'scale': [initial_pix_size*32,initial_pix_size*32]},\n",
    "         {'type': 'translation', 'translation': [0, 0]}],\n",
    "        ]\n",
    "axes = [{'name': 'y', 'type': 'space', 'unit': initial_pix_unit},\n",
    "        {'name': 'x', 'type': 'space', 'unit': initial_pix_unit}]\n",
    "\n",
    "# Open the zarr group manually\n",
    "path_str = \"./data/\"+section+\"corr-ome.zarr\"\n",
    "path = Path(path_str)\n",
    "\n",
    "if path.exists():\n",
    "  rm_tree(path)\n",
    "\n",
    "store = parse_url(path, mode='w').store\n",
    "root = zarr.group(store=store)\n",
    "\n",
    "# Use OME write multiscale;\n",
    "write_multiscale([d0, d1, d2, d3, d4, d5],\n",
    "        group=root, axes=axes, coordinate_transformations=coordtfs\n",
    "        )\n",
    "# add omero metadata: the napari ome-zarr plugin uses this to pass rendering\n",
    "# options to napari.\n",
    "root.attrs['omero'] = {\n",
    "        'channels': [{\n",
    "                'color': 'ffffff',\n",
    "                'label': region,\n",
    "                'active': True,\n",
    "                }]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if z0_path.exists():\n",
    "  rm_tree(z0_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
